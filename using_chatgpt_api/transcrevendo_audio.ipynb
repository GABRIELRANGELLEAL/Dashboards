{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6091c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv # lib utilizada para carregar as variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ceddb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "    # O código acima serve para carregar as variáveis de ambiente definidas em um arquivo `.env` para o ambiente do Python.\n",
    "    # Isso é útil para acessar informações sensíveis, como chaves de API, sem expô-las diretamente no código.\n",
    "    # A função `find_dotenv()` localiza automaticamente o arquivo `.env` na estrutura de diretórios do projeto,\n",
    "    # e `load_dotenv()` carrega as variáveis desse arquivo para serem usadas no restante do código.\n",
    "\n",
    "client = openai.OpenAI() # Cria uma instância do cliente OpenAI para interagir com a API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9d13d",
   "metadata": {},
   "source": [
    "Agora realmente vamos começar a transcrever um áudio que a dinda me enviou pra testar a lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df82e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.audio.transcription.Transcription"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Abre o arquivo de áudio 'audio_dinda.ogg' no modo de leitura binária ('rb')\n",
    "arquivo_audio = open('audio_dinda.mp4', 'rb') \n",
    "# agora entra o código para acessar os modelos da openai\n",
    "transcricao = client.audio.transcriptions.create(\n",
    "    model = 'whisper-1',\n",
    "    language = 'pt',\n",
    "    file = arquivo_audio\n",
    ")\n",
    "type(transcricao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43cc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantas pessoas estão? Qual é o grupo que tu tá?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create an a function that turn our life more easy\n",
    "def audio_transcribe(file_path, model = 'whisper-1', language = 'pt'):\n",
    "    with open('audio_dinda.mp4', 'rb') as audio_file:\n",
    "        transcricao = client.audio.transcriptions.create(\n",
    "            model = 'whisper-1',\n",
    "            language = 'pt',\n",
    "            file = arquivo_audio\n",
    "        )\n",
    "    return transcricao.text\n",
    "    \n",
    "audio_transcribe('audio_dinda.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda899a",
   "metadata": {},
   "source": [
    "Agora vamos aprender a conversar com o chatgpt usando back end\n",
    "\n",
    "Para mais informações de como o chat gera texto a partir de texto: https://platform.openai.com/docs/guides/text?prompt-templates-examples=simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf17523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_answare(user_input: str, developer_input: str, model: str = \"gpt-5-nano\", reasoning: dict = {\"effort\": \"low\"}):\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        reasoning=reasoning,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"developer\",\n",
    "                \"content\": f\"{developer_input}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{user_input}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "user_input = 'Quantas pessoas estão? Qual é o grupo que tu tá?'\n",
    "developer_input = 'Voce vai retornar com uma resposta curta, no máximo 5 palavras, mostrando qual sentimento voce coletou do input do usuario'\n",
    "response = chat_answare(user_input = user_input, developer_input=developer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9934ad3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_68acd66064448194be837c61582e32fe0f4c6b013658f170', created_at=1756157536.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_68acd66154d88194ab5ae80e7d25676d0f4c6b013658f170', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_68acd66229208194ac047c75811ae16d0f4c6b013658f170', content=[ResponseOutputText(annotations=[], text='Neutro', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='low', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=48, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=137, output_tokens_details=OutputTokensDetails(reasoning_tokens=128), total_tokens=185), user=None, store=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdade83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Response(\n",
    "    id='resp_68a72bd8592c8194b62a5961c4bd1e110506d971775469e5',\n",
    "    created_at=1755786200.0,\n",
    "    error=None,\n",
    "    incomplete_details=None,\n",
    "    instructions=None,\n",
    "    metadata={},\n",
    "    model='gpt-5-nano-2025-08-07',\n",
    "    object='response',\n",
    "    output=[\n",
    "        ResponseReasoningItem(\n",
    "            id='rs_68a72bd90c9881949696effbe524bd810506d971775469e5',\n",
    "            summary=[],\n",
    "            type='reasoning',\n",
    "            content=None,\n",
    "            encrypted_content=None,\n",
    "            status=None\n",
    "        ),\n",
    "        ResponseOutputMessage(\n",
    "            id='msg_68a72bda1b348194b99a210235f3af4f0506d971775469e5',\n",
    "            content=[\n",
    "                ResponseOutputText(annotations=[],\n",
    "                text='Sentimento: neutro.',\n",
    "                type='output_text',\n",
    "                logprobs=[])\n",
    "            ],\n",
    "            role='assistant',\n",
    "            status='completed',\n",
    "            type='message'\n",
    "        )\n",
    "    ],\n",
    "    parallel_tool_calls=True,\n",
    "    temperature=1.0,\n",
    "    tool_choice='auto',\n",
    "    tools=[],\n",
    "    top_p=1.0,\n",
    "    background=False,\n",
    "    max_output_tokens=None,\n",
    "    max_tool_calls=None,\n",
    "    previous_response_id=None,\n",
    "    prompt=None,\n",
    "    prompt_cache_key=None,\n",
    "    reasoning=Reasoning(\n",
    "        effort='low',\n",
    "        generate_summary=None,\n",
    "        summary=None\n",
    "    ),\n",
    "    safety_identifier=None,\n",
    "    service_tier='default',\n",
    "    status='completed',\n",
    "    text=ResponseTextConfig(\n",
    "        format=ResponseFormatText(type='text'),\n",
    "        verbosity='medium'\n",
    "    ),\n",
    "    top_logprobs=0,\n",
    "    truncation='disabled',\n",
    "    usage=ResponseUsage(\n",
    "        input_tokens=48,\n",
    "        input_tokens_details=InputTokensDetails(cached_tokens=0),\n",
    "        output_tokens=204,\n",
    "        output_tokens_details=OutputTokensDetails(reasoning_tokens=192),\n",
    "        total_tokens=252\n",
    "    ),\n",
    "    user=None,\n",
    "    store=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
